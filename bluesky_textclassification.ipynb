{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eK3RqyDsIA_"
      },
      "source": [
        "## Vorbereiten des Datensatzes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBb6PWR3RaOE"
      },
      "source": [
        "Teile des Codes sind aus den Projekten \"fine_tuning_huggingface\" und \"evaluation\" aus der Übung für Informationswissenschaft 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DhUFZFRaT28",
        "outputId": "02948283-b49a-4a57-caa0-b7c2cbed2e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers\n",
        "!pip install accelerate\n",
        "!pip install evaluate datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MFZnZp2XCiN",
        "outputId": "370501bf-46cb-4c9e-ca01-2afb274ec196"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.stats import ttest_rel\n",
        "import evaluate\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import pipeline\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from evaluate import evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3irqx96BA0qZ"
      },
      "source": [
        "Entfernen von HTML und XML Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzdxUykbM7H_"
      },
      "outputs": [],
      "source": [
        "def remove_xml_tags(review_text):\n",
        "  if isinstance(review_text, str):\n",
        "    return BeautifulSoup(review_text, \"lxml\").text\n",
        "  else:\n",
        "    return \"\" # Return an empty string for non-string values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lryTPgmhRWnF"
      },
      "source": [
        "Das Mapping war in diesem Fall nicht notwendig, da die Spalte Label während des manuellen labelns bereits als integer gespeichert wurde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q5dHvb8MgQV"
      },
      "outputs": [],
      "source": [
        "# Label-Mapping definieren\n",
        "label_mapping = {0 : 0, 1 : 1, 2 : 2}\n",
        "\n",
        "# Funktion für das Mapping von String zu Integer erstellen\n",
        "def map_label(label):\n",
        "    return label_mapping.get(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn1LMD-TAep2"
      },
      "source": [
        "Dieser Code dient dazu, Serviceposts von Bluesky im Vorfeld zu entfernen, da diese für das Ergebnis nicht relevant sind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW-fHISc_jiu"
      },
      "outputs": [],
      "source": [
        "# CSV-Datei einlesen\n",
        "df = pd.read_csv('/content/filtered_feeds.csv')\n",
        "\n",
        "\n",
        "# Beispiel 2: Zeilen entfernen, die bestimmte Wörter oder Phrasen enthalten (z. B. \"uninteressant\", \"test\")\n",
        "uninteressante_woerter = ['Trending Words', 'past usage']\n",
        "df = df[~df['text'].str.contains('|'.join(uninteressante_woerter), na=False)]\n",
        "\n",
        "# Ergebnis speichern (optional)\n",
        "df.to_csv('/content/bereinigte_datei.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdj7Ysj4mIwK"
      },
      "source": [
        "Die Spalten author und created_at werden entfernt, da diese für die weitere Bearbeitung nicht benötigt werden.\n",
        "Das Mapping der Spalte label ist in diesem Fall deaktiviert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X_viTXx-pUG",
        "outputId": "1d088b47-d0fb-40a0-a24d-332406945a7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-1ebc44ffde6e>:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  return BeautifulSoup(review_text, \"lxml\").text\n",
            "<ipython-input-3-1ebc44ffde6e>:3: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  return BeautifulSoup(review_text, \"lxml\").text\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    text  label\n",
            "0      Habe gerade meinen Wahlschein für die Europawa...      0\n",
            "1      Der Wahl-O-Mat zur Europawahl 2024 geht am 7. ...      0\n",
            "2      Mein Ergebnis zur #Europawahl bei #Wahlswiper ...      0\n",
            "3      Hattet Ihr schon Benachrichtigungen im Briefka...      0\n",
            "4                                                   Nein      0\n",
            "...                                                  ...    ...\n",
            "17497  Ich wähle SPD und Grüne, auch wenn ich nach de...      2\n",
            "17498  Herzlich Willkommen. Ich bin auch im März beig...      2\n",
            "17499  Direkt als Stadtrat kandidieren. Da geht dann ...      2\n",
            "17500                                           Supi! 👍🏻      2\n",
            "17501  Tja, die Niederländer scheinen da schon wieder...      2\n",
            "\n",
            "[17502 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "bluesky_tweet_dataset = pd.read_csv(\"/content/bereinigte_datei.csv\",\n",
        "                                    delimiter=\",\",\n",
        "                                    encoding='utf-8',\n",
        "                                    names=['author', 'text', 'created_at', 'label'],\n",
        "                                    skiprows=1)\n",
        "bluesky_tweet_dataset['text'] = bluesky_tweet_dataset['text'].apply(remove_xml_tags)\n",
        "# bluesky_tweet_dataset['label'] = bluesky_tweet_dataset['label'].apply(map_label)\n",
        "bluesky_tweet_dataset = bluesky_tweet_dataset.drop(columns=['author'])\n",
        "bluesky_tweet_dataset = bluesky_tweet_dataset.drop(columns=['created_at'])\n",
        "\n",
        "print(bluesky_tweet_dataset)\n",
        "\n",
        "\n",
        "# Aufteilung des Datensatzes in train, test und dev (80% train, 10% test, 10% dev)\n",
        "train_df, test_dev_df = train_test_split(bluesky_tweet_dataset, test_size=0.2, random_state=42)\n",
        "dev_df, test_df = train_test_split(test_dev_df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdNafFWMAQcQ",
        "outputId": "2248c05c-c114-42e2-b345-17b6f7a484e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 14001\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1750\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1751\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Umwandlung jedes Splits in ein Dataset-Objekt\n",
        "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "dev_dataset = Dataset.from_pandas(dev_df, preserve_index=False)\n",
        "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)\n",
        "\n",
        "# Die einzelnen Splits werden in ein Dictionary zusammengefügt, wodurch die\n",
        "# weitere Verarbeitung vereinfacht wird\n",
        "bluesky_tweet_dict = DatasetDict({\"train\": train_dataset, \"dev\": dev_dataset, \"test\": test_dataset})\n",
        "bluesky_tweet_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6MnvYHKrpqv"
      },
      "source": [
        "Im Anschluss ein Beispiel, wie eine Reihe im Traingisdatensatz aussieht:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKb29fIFBGUZ",
        "outputId": "12f44a33-5c25-4f42-c2fe-671ce86f2711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Das Desaster der Grünen bei der Europawahl belebt den alten Konflikt zwischen Realo-Flügel und Fundamentalisten neu. Die Realos hadern mit der Parteispitze und werfen ihr strategische Schwächen sowie eine verfehlte Wahlkampfführung vor.Von FOCUS-online-Autor Hans-Jürgen Moritz',\n",
              " 'label': 1}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bluesky_tweet_dataset = bluesky_tweet_dict['train']\n",
        "bluesky_tweet_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBVivUtwTOu-",
        "outputId": "15e2f634-99e4-4c71-8f6b-a685d7bc8ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Value(dtype='int64', id=None)}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bluesky_tweet_dataset.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzz7VB8Am6T6"
      },
      "source": [
        "Das erste Model, welches trainiert wird, ist deepset/gbert-base. Es handelt sich um ein Deutsches BERT Modell.\n",
        "\n",
        "Der Rohtext wird durch den Tokenizer in Zahlenformat überführt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9IDe7cWBftM",
        "outputId": "64a2d131-51db-4da3-864a-56fc62ad1099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "checkpoint = \"deepset/gbert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SrEGrvMBqUX"
      },
      "outputs": [],
      "source": [
        "# Erstellung einer Tokenisierungsfunktion\n",
        "def tokenize_function(batch):\n",
        "  return tokenizer(batch[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "707f0f7fe86e472bbb28b39ab77bac7d",
            "c80acc03e35a40b8a33a4573b34693eb",
            "dde31b59939d4c8fab3529a00535e88e",
            "05602fb4c1ab43f5924a3288294c7627",
            "649775818c2d45d7a613ad85aa2287f6",
            "e089c685b0bf499a9481afbb92f1d273",
            "c453a2bb44a94d72bcc89a4e446ee153",
            "fd0c286cee574fddbf4b555b6a4d5a99",
            "0f860935ee41463db53710002ceb422f",
            "03db24dda2fa4f30a0d1390d12302cdc",
            "a8792f72caa34300b3883634e54c8e06",
            "fe89fabcff924d8c91d89eafa6f5d21b",
            "c1057ede333d472e928bf26f119363a8",
            "5291ad402b5e49ccb9901fbd01b22fd5",
            "920ce00a1ab94bb881fe720826d11b25",
            "37d5bcfa8baf49a8a7cb4319e4878644",
            "47c2135deb1e4a549d535f651217e350",
            "e67f7bb84bb043039e55446bf4f0dbb9",
            "21a398f9e0ca477794b4158c496082c9",
            "c60794530aae437fa1a4959a2da15891",
            "59536dd194824a6a88ed087866125598",
            "b21cbc94a5c044598ea240105625a58e",
            "81534daa4bb34ff48343ab8e9e3845e4",
            "70869ba006314eada3d7a3b1a4c1c00e",
            "71b22bfcbc3b4e4a9ec5baa8b1c3cbe5",
            "babf699761d6423790309aa5cf8f501c",
            "313c52dfb21b49149206d7df944c3d59",
            "33247d2e0e9f42dfa8f5aa605dcd197d",
            "0b8f1ecb456c409c837e586ebd474433",
            "2c28e062485a4779871a62b9ef881619",
            "640c3cf334934cc08e8460e162a615a6",
            "a712f98ca93340af9e4c8b43c642b1ca",
            "7db65dc6f8de48328a9835da2bc84a9d"
          ]
        },
        "id": "hovY50qe8wp2",
        "outputId": "ab5609c4-ae4c-40cd-834d-031582ae91c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "707f0f7fe86e472bbb28b39ab77bac7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14001 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe89fabcff924d8c91d89eafa6f5d21b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1750 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81534daa4bb34ff48343ab8e9e3845e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1751 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dataset.map-Methode, damit Funktion auf jedes Element im Datensatz angewendet werden kann\n",
        "tokenized_datasets = bluesky_tweet_dict.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZCcls9UCIdb"
      },
      "outputs": [],
      "source": [
        "# Dynamisches Padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r75SNqxus4la"
      },
      "source": [
        "## Training und erste Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFClGFNNCUx2",
        "outputId": "5cedb19d-e0ba-4f34-8450-518456949765"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Auswahl der Klasse für den Classification Head\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwqqSDD0Cb3t"
      },
      "outputs": [],
      "source": [
        "# Methode, um das Modell später evaluieren zu können\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"macro\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  precision = precision_score(labels, preds, average=\"macro\")\n",
        "  recall = recall_score(labels, preds, average=\"macro\")\n",
        "  return {\"precision\": precision, \"recall\": recall, \"acc\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q2Bd82PDKNT",
        "outputId": "b043ea5f-b370-4a5b-a6aa-71d949e948ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Spezifizierung der Trainingsdaten\n",
        "batch_size = 32\n",
        "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = f\"{checkpoint}-finetuned-tweets\"\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  num_train_epochs = 4,\n",
        "                                  learning_rate = 2e-5,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm = False,\n",
        "                                  logging_steps = logging_steps,\n",
        "                                  log_level=\"info\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygC00BvfNxFJ",
        "outputId": "e88ef5f2-ed5d-4aa9-df4e-22326c3a82e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14001\n",
            "1751\n",
            "1750\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_datasets[\"train\"]))\n",
        "print(len(tokenized_datasets[\"test\"]))\n",
        "print(len(tokenized_datasets[\"dev\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpRUnZ5QD8Qu"
      },
      "outputs": [],
      "source": [
        "# Übergabe aller wichtigen Parameter im Trainer\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "zmqhD8lFD7ZY",
        "outputId": "1cc14caa-6628-49ff-e82d-7d595f8d4358"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 14,001\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1,752\n",
            "  Number of trainable parameters = 109,929,987\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1752' max='1752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1752/1752 17:05, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.671100</td>\n",
              "      <td>0.600977</td>\n",
              "      <td>0.724827</td>\n",
              "      <td>0.751834</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.734957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.504500</td>\n",
              "      <td>0.603467</td>\n",
              "      <td>0.743074</td>\n",
              "      <td>0.771363</td>\n",
              "      <td>0.757714</td>\n",
              "      <td>0.753917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.379700</td>\n",
              "      <td>0.655502</td>\n",
              "      <td>0.739389</td>\n",
              "      <td>0.764263</td>\n",
              "      <td>0.753714</td>\n",
              "      <td>0.749391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.293400</td>\n",
              "      <td>0.720836</td>\n",
              "      <td>0.729297</td>\n",
              "      <td>0.755978</td>\n",
              "      <td>0.744000</td>\n",
              "      <td>0.739942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to deepset/gbert-base-finetuned-tweets/checkpoint-500\n",
            "Configuration saved in deepset/gbert-base-finetuned-tweets/checkpoint-500/config.json\n",
            "Model weights saved in deepset/gbert-base-finetuned-tweets/checkpoint-500/model.safetensors\n",
            "tokenizer config file saved in deepset/gbert-base-finetuned-tweets/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in deepset/gbert-base-finetuned-tweets/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to deepset/gbert-base-finetuned-tweets/checkpoint-1000\n",
            "Configuration saved in deepset/gbert-base-finetuned-tweets/checkpoint-1000/config.json\n",
            "Model weights saved in deepset/gbert-base-finetuned-tweets/checkpoint-1000/model.safetensors\n",
            "tokenizer config file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to deepset/gbert-base-finetuned-tweets/checkpoint-1500\n",
            "Configuration saved in deepset/gbert-base-finetuned-tweets/checkpoint-1500/config.json\n",
            "Model weights saved in deepset/gbert-base-finetuned-tweets/checkpoint-1500/model.safetensors\n",
            "tokenizer config file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to deepset/gbert-base-finetuned-tweets/checkpoint-1752\n",
            "Configuration saved in deepset/gbert-base-finetuned-tweets/checkpoint-1752/config.json\n",
            "Model weights saved in deepset/gbert-base-finetuned-tweets/checkpoint-1752/model.safetensors\n",
            "tokenizer config file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1752/tokenizer_config.json\n",
            "Special tokens file saved in deepset/gbert-base-finetuned-tweets/checkpoint-1752/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1752, training_loss=0.46178420792975927, metrics={'train_runtime': 1028.1179, 'train_samples_per_second': 54.472, 'train_steps_per_second': 1.704, 'total_flos': 2660999605765704.0, 'train_loss': 0.46178420792975927, 'epoch': 4.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Durchführung des Trainings\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RiJaYTyWEYpN",
        "outputId": "d01da314-5b7f-4e73-c00e-7a008f1ff5a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to deepset/gbert-base-finetuned-tweets\n",
            "Configuration saved in deepset/gbert-base-finetuned-tweets/config.json\n",
            "Model weights saved in deepset/gbert-base-finetuned-tweets/model.safetensors\n",
            "tokenizer config file saved in deepset/gbert-base-finetuned-tweets/tokenizer_config.json\n",
            "Special tokens file saved in deepset/gbert-base-finetuned-tweets/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "# Speicherung des Modells\n",
        "trainer.save_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ykIvhlPpEdW1",
        "outputId": "a15ae4a5-5ede-45dd-d076-4eb601b01061"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1751\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.692859411239624,\n",
              " 'eval_precision': 0.7382159886061057,\n",
              " 'eval_recall': 0.7523098791755508,\n",
              " 'eval_acc': 0.7498572244431754,\n",
              " 'eval_f1': 0.7444688485358343,\n",
              " 'eval_runtime': 8.7083,\n",
              " 'eval_samples_per_second': 201.072,\n",
              " 'eval_steps_per_second': 6.316,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Das Modell wird mit einem Test-Datensatz validiert, um zu überprüfen, wie robust es ist.\n",
        "trainer.evaluate(eval_dataset=tokenized_datasets['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3txxBIOMJ-G"
      },
      "source": [
        "Die Ergebnisse von 'test' und 'dev' sind sich ähnlich, somit liegt kein Fehler auf unserer Seite vor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXhunDYNtROB"
      },
      "source": [
        "### 1.4 Vergleich mit anderem Modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJphyMSwQTy7"
      },
      "source": [
        "Nachdem wir das erste Modell trainiert haben, wird nun das zweite Modell ebenfalls auf die gleiche Weise trainiert, um zu überprüfen, welches der beiden Modelle besser abschneidet.\n",
        "\n",
        "Als zweites Modell wurde german-sentiment-bert gewählt, da dieses bereits auf verschiedenen Plattformen wie beispielsweise X (Twitter) und Facebook trainiert wurde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U_UovYEPejm_",
        "outputId": "f295f0aa-1e32-4f29-95c4-9d337b6cb9b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"oliverguhr/german-sentiment-bert\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"germansentiment\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"positive\",\n",
            "    \"1\": \"negative\",\n",
            "    \"2\": \"neutral\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"negative\": 1,\n",
            "    \"neutral\": 2,\n",
            "    \"positive\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"oliverguhr/german-sentiment-bert\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"germansentiment\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"positive\",\n",
            "    \"1\": \"negative\",\n",
            "    \"2\": \"neutral\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"negative\": 1,\n",
            "    \"neutral\": 2,\n",
            "    \"positive\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"oliverguhr/german-sentiment-bert\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"germansentiment\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"positive\",\n",
            "    \"1\": \"negative\",\n",
            "    \"2\": \"neutral\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"negative\": 1,\n",
            "    \"neutral\": 2,\n",
            "    \"positive\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "checkpoint_german_sentiment_bert = \"oliverguhr/german-sentiment-bert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_german_sentiment_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "3774492a79004ad8bbf2bfa074d3f140",
            "c7e438fb5be948cd9f0203ac86c3844d",
            "1f748b43b0874326a03143c57e388d60"
          ]
        },
        "id": "XdMyEtSuek3G",
        "outputId": "bc6fcd13-6a95-49bb-9396-a6ee9b4748f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3774492a79004ad8bbf2bfa074d3f140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14001 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7e438fb5be948cd9f0203ac86c3844d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1750 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f748b43b0874326a03143c57e388d60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1751 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dataset.map-Methode, damit Funktion auf jedes Element im Datensatz angewendet werden kann\n",
        "tokenized_datasets = bluesky_tweet_dict.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ngaPKQoBek6r"
      },
      "outputs": [],
      "source": [
        "# Dynamisches Padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OcSzMMwZek97",
        "outputId": "c32fe49d-cc5c-4040-e6b9-5ebe8167f7ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"oliverguhr/german-sentiment-bert\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"finetuning_task\": \"germansentiment\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"positive\",\n",
            "    \"1\": \"negative\",\n",
            "    \"2\": \"neutral\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"negative\": 1,\n",
            "    \"neutral\": 2,\n",
            "    \"positive\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--oliverguhr--german-sentiment-bert/snapshots/f195511fd2678d4a56ca3f5a371844138a3bc8d9/model.safetensors\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at oliverguhr/german-sentiment-bert.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Auswahl der Klasse für den Classification Head\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_german_sentiment_bert, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FTQvweDselGR",
        "outputId": "0f144582-83f0-42b3-e732-1e29d2a8b589"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "# Spezifizierung der Trainingsdaten\n",
        "batch_size = 32\n",
        "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = f\"{checkpoint_german_sentiment_bert}-finetuned-tweets\"\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  num_train_epochs = 4,\n",
        "                                  learning_rate = 2e-5,\n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm = False,\n",
        "                                  logging_steps = logging_steps,\n",
        "                                  log_level=\"info\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eMoW0--pelJa"
      },
      "outputs": [],
      "source": [
        "# Übergabe aller wichtigen Parameter im Trainer\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"dev\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rZXoH3ODelMg",
        "outputId": "dab764f0-0f74-47c2-f589-9bd923d65c36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 14,001\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1,752\n",
            "  Number of trainable parameters = 109,083,651\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1752' max='1752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1752/1752 17:34, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Acc</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.816800</td>\n",
              "      <td>0.702637</td>\n",
              "      <td>0.687452</td>\n",
              "      <td>0.684219</td>\n",
              "      <td>0.696571</td>\n",
              "      <td>0.684898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.644100</td>\n",
              "      <td>0.721215</td>\n",
              "      <td>0.680512</td>\n",
              "      <td>0.702899</td>\n",
              "      <td>0.696571</td>\n",
              "      <td>0.689474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.548400</td>\n",
              "      <td>0.735627</td>\n",
              "      <td>0.682051</td>\n",
              "      <td>0.688926</td>\n",
              "      <td>0.694857</td>\n",
              "      <td>0.685195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.476100</td>\n",
              "      <td>0.772983</td>\n",
              "      <td>0.682901</td>\n",
              "      <td>0.689295</td>\n",
              "      <td>0.694857</td>\n",
              "      <td>0.685868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-500\n",
            "Configuration saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-500/config.json\n",
            "Model weights saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-500/model.safetensors\n",
            "tokenizer config file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1000\n",
            "Configuration saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1000/config.json\n",
            "Model weights saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1000/model.safetensors\n",
            "tokenizer config file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1500\n",
            "Configuration saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1500/config.json\n",
            "Model weights saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1500/model.safetensors\n",
            "tokenizer config file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1752\n",
            "Configuration saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1752/config.json\n",
            "Model weights saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1752/model.safetensors\n",
            "tokenizer config file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1752/tokenizer_config.json\n",
            "Special tokens file saved in oliverguhr/german-sentiment-bert-finetuned-tweets/checkpoint-1752/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1750\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1752, training_loss=0.6210113193618653, metrics={'train_runtime': 1054.8131, 'train_samples_per_second': 53.094, 'train_steps_per_second': 1.661, 'total_flos': 2779586673151932.0, 'train_loss': 0.6210113193618653, 'epoch': 4.0})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Durchführung des Trainings\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2xf5YqZelRv"
      },
      "outputs": [],
      "source": [
        "# Speicherung des Modells\n",
        "trainer.save_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-d57MJtqP_A"
      },
      "outputs": [],
      "source": [
        "print(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsyISSDEfG2p"
      },
      "outputs": [],
      "source": [
        "# Das Modell wird mit einem Test-Datensatz validiert, um zu überprüfen, wie robust es ist.\n",
        "trainer.evaluate(eval_dataset=tokenized_datasets['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7tL_-PljJqN"
      },
      "source": [
        "Die Ergebnisse von test und dev sind sich wieder sehr ähnlich. Jedoch ist zu bemerken, dass die Ergebnisse unseres ersten Modells höhere Werte aufweisen, und somit möglicherweise besser geeignet ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiGtxWIfoZPO"
      },
      "source": [
        "## WordClouds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV1tenCzobzo"
      },
      "source": [
        "Um eine visuelle Darstellung der häufigsten Wörter der jeweiligen Label zu erhalten, haben wir WordClouds erstellt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2A8fgxKiqnF"
      },
      "outputs": [],
      "source": [
        "# Filter the tweets based on sentiment label\n",
        "neutral_tweets = bluesky_tweet_dataset.filter(lambda example: example['label'] == 0)['text']\n",
        "negative_tweets = bluesky_tweet_dataset.filter(lambda example: example['label'] == 1)['text']\n",
        "positive_tweets = bluesky_tweet_dataset.filter(lambda example: example['label'] == 2)['text']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nI5KOXGit9G"
      },
      "outputs": [],
      "source": [
        "# Combine text into single strings\n",
        "neutral_tweets = ' '.join(neutral_tweets)\n",
        "negative_tweets = ' '.join(negative_tweets)\n",
        "positive_tweets = ' '.join(positive_tweets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQV6Dfiit5z"
      },
      "outputs": [],
      "source": [
        "# Define stopwords (in German and English)\n",
        "stop_words = set(stopwords.words('german') + stopwords.words('english'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c78JrOcCit1O"
      },
      "outputs": [],
      "source": [
        "# Generate word clouds for each sentiment class\n",
        "wordcloud_neutral = WordCloud(stopwords=stop_words, background_color=\"white\").generate(neutral_tweets)\n",
        "wordcloud_negative = WordCloud(stopwords=stop_words, background_color=\"white\").generate(negative_tweets)\n",
        "wordcloud_positive = WordCloud(stopwords=stop_words, background_color=\"white\").generate(positive_tweets)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu8bNI-6itup"
      },
      "outputs": [],
      "source": [
        "# Plot word clouds side by side\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(wordcloud_neutral, interpolation='bilinear')\n",
        "axs[0].set_title('Neutrale Posts')\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(wordcloud_negative, interpolation='bilinear')\n",
        "axs[1].set_title('Negative Posts')\n",
        "axs[1].axis('off')\n",
        "\n",
        "axs[2].imshow(wordcloud_positive, interpolation='bilinear')\n",
        "axs[2].set_title('Positive Posts')\n",
        "axs[2].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeNpuNMAitk0"
      },
      "outputs": [],
      "source": [
        "axs[1].imshow(wordcloud_negative, interpolation='bilinear')\n",
        "axs[1].set_title('Negative Tweets')\n",
        "axs[1].axis('off')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVQioH51yPrP"
      },
      "outputs": [],
      "source": [
        "axs[2].imshow(wordcloud_positive, interpolation='bilinear')\n",
        "axs[2].set_title('Positive Tweets')\n",
        "axs[2].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aFMRSKgpj_O"
      },
      "source": [
        "## Weitere Evaluation der Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOSMcDNZZO5l"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", model=\"deepset/gbert-base\", device=0) # Laden des Modells\n",
        "data = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000)) # Laden des Datensatzes, Wahl des test-Splits\n",
        "metric = evaluate.load(\"accuracy\") # Verwendung der Accuracy-Metrik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFZA_1jSZO3h"
      },
      "outputs": [],
      "source": [
        "# Erstellen eines Evaluators für die Textklassifikation\n",
        "evaluator_instance = evaluate.evaluator(\"text-classification\")\n",
        "\n",
        "\n",
        "# Instead of hardcoding, dynamically get the label2id mapping from the model's config\n",
        "# Assuming your model (pipe) has a 'config' attribute with 'id2label' or 'label2id'\n",
        "if hasattr(pipe.model.config, 'id2label'):\n",
        "    id2label = pipe.model.config.id2label\n",
        "elif hasattr(pipe.model.config, 'label2id'):\n",
        "    # Invert label2id to get id2label if id2label is not directly available\n",
        "    label2id = pipe.model.config.label2id\n",
        "    id2label = {id: label for label, id in label2id.items()}\n",
        "else:\n",
        "    raise ValueError(\"Model config does not contain 'id2label' or 'label2id'\")\n",
        "\n",
        "# Create label_mapping from id2label\n",
        "label_mapping = {label: id for id, label in id2label.items()}\n",
        "\n",
        "\n",
        "# Durchführen der Evaluation\n",
        "results = evaluator_instance.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=data,\n",
        "    metric=metric,\n",
        "    label_mapping=label_mapping,  # Use the generated label_mapping\n",
        ")\n",
        "\n",
        "# Ausgabe des Ergebnisses\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbQXdOFAZO13"
      },
      "outputs": [],
      "source": [
        "results = evaluator_instance.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=data,\n",
        "    metric=metric,\n",
        "    label_mapping=label_mapping,  # Use the model's label mapping\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200,\n",
        ")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anxSMVAdZlTP"
      },
      "source": [
        "Das Berechnen eines Werts ist oft nicht ausreichend, um aussagen zu können, ob ein Modell signifikant besser performt als ein anderes. Dafür eignet sich **Bootstrapping**. Mit dieser Methode können Konfidenzintervalle sowie Standardabweichung errechnet werden. Der tatsächliche Wert wird dadurch viel stabiler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riEnmAqbZ6Tg"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", model=\"oliverguhr/german-sentiment-bert\", device=0) # Laden des Modells\n",
        "data = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000)) # Laden des Datensatzes, Wahl des test-Splits\n",
        "metric = evaluate.load(\"accuracy\") # Verwendung der Accuracy-Metrik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS0fxF23ZOz4"
      },
      "outputs": [],
      "source": [
        "eval = evaluator(\"text-classification\") # Erstellen eines Evaluators für die Textklassifikation\n",
        "\n",
        "results = eval.compute(model_or_pipeline=pipe,\n",
        "                       data=data,\n",
        "                       metric=metric,\n",
        "                       label_mapping={\"neutral\" : 0, \"negative\": 1, \"positive\": 2}, # Updated label_mapping with correct keys\n",
        "                       ) # Durchführen der Evaluation\n",
        "\n",
        "print(results) # Ausgabe des Ergebnisses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB_ysIYVZOwg"
      },
      "outputs": [],
      "source": [
        "results = eval.compute(model_or_pipeline=pipe,\n",
        "                       data=data,\n",
        "                       metric=metric,\n",
        "                       label_mapping={\"neutral\" : 0, \"negative\": 1, \"positive\": 2}, # Changed keys to lowercase\n",
        "                       strategy=\"bootstrap\", n_resamples=200)\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp1vctprZx9U"
      },
      "source": [
        "Die Werte des Modells gbert-base sind höher als die Werte des Modells german-sentiment-bert, was darauf schließen lässt, dass ersteres Modell besser geeignet ist."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03db24dda2fa4f30a0d1390d12302cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05602fb4c1ab43f5924a3288294c7627": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03db24dda2fa4f30a0d1390d12302cdc",
            "placeholder": "​",
            "style": "IPY_MODEL_a8792f72caa34300b3883634e54c8e06",
            "value": " 14001/14001 [00:03&lt;00:00, 4516.09 examples/s]"
          }
        },
        "0b8f1ecb456c409c837e586ebd474433": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f860935ee41463db53710002ceb422f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21a398f9e0ca477794b4158c496082c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c28e062485a4779871a62b9ef881619": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313c52dfb21b49149206d7df944c3d59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33247d2e0e9f42dfa8f5aa605dcd197d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d5bcfa8baf49a8a7cb4319e4878644": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c2135deb1e4a549d535f651217e350": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5291ad402b5e49ccb9901fbd01b22fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a398f9e0ca477794b4158c496082c9",
            "max": 1750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c60794530aae437fa1a4959a2da15891",
            "value": 1750
          }
        },
        "59536dd194824a6a88ed087866125598": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640c3cf334934cc08e8460e162a615a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "649775818c2d45d7a613ad85aa2287f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707f0f7fe86e472bbb28b39ab77bac7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c80acc03e35a40b8a33a4573b34693eb",
              "IPY_MODEL_dde31b59939d4c8fab3529a00535e88e",
              "IPY_MODEL_05602fb4c1ab43f5924a3288294c7627"
            ],
            "layout": "IPY_MODEL_649775818c2d45d7a613ad85aa2287f6"
          }
        },
        "70869ba006314eada3d7a3b1a4c1c00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33247d2e0e9f42dfa8f5aa605dcd197d",
            "placeholder": "​",
            "style": "IPY_MODEL_0b8f1ecb456c409c837e586ebd474433",
            "value": "Map: 100%"
          }
        },
        "71b22bfcbc3b4e4a9ec5baa8b1c3cbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c28e062485a4779871a62b9ef881619",
            "max": 1751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_640c3cf334934cc08e8460e162a615a6",
            "value": 1751
          }
        },
        "7db65dc6f8de48328a9835da2bc84a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81534daa4bb34ff48343ab8e9e3845e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70869ba006314eada3d7a3b1a4c1c00e",
              "IPY_MODEL_71b22bfcbc3b4e4a9ec5baa8b1c3cbe5",
              "IPY_MODEL_babf699761d6423790309aa5cf8f501c"
            ],
            "layout": "IPY_MODEL_313c52dfb21b49149206d7df944c3d59"
          }
        },
        "920ce00a1ab94bb881fe720826d11b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59536dd194824a6a88ed087866125598",
            "placeholder": "​",
            "style": "IPY_MODEL_b21cbc94a5c044598ea240105625a58e",
            "value": " 1750/1750 [00:00&lt;00:00, 3494.32 examples/s]"
          }
        },
        "a712f98ca93340af9e4c8b43c642b1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8792f72caa34300b3883634e54c8e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b21cbc94a5c044598ea240105625a58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "babf699761d6423790309aa5cf8f501c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a712f98ca93340af9e4c8b43c642b1ca",
            "placeholder": "​",
            "style": "IPY_MODEL_7db65dc6f8de48328a9835da2bc84a9d",
            "value": " 1751/1751 [00:00&lt;00:00, 4050.80 examples/s]"
          }
        },
        "c1057ede333d472e928bf26f119363a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c2135deb1e4a549d535f651217e350",
            "placeholder": "​",
            "style": "IPY_MODEL_e67f7bb84bb043039e55446bf4f0dbb9",
            "value": "Map: 100%"
          }
        },
        "c453a2bb44a94d72bcc89a4e446ee153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c60794530aae437fa1a4959a2da15891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c80acc03e35a40b8a33a4573b34693eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e089c685b0bf499a9481afbb92f1d273",
            "placeholder": "​",
            "style": "IPY_MODEL_c453a2bb44a94d72bcc89a4e446ee153",
            "value": "Map: 100%"
          }
        },
        "dde31b59939d4c8fab3529a00535e88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0c286cee574fddbf4b555b6a4d5a99",
            "max": 14001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f860935ee41463db53710002ceb422f",
            "value": 14001
          }
        },
        "e089c685b0bf499a9481afbb92f1d273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e67f7bb84bb043039e55446bf4f0dbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd0c286cee574fddbf4b555b6a4d5a99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe89fabcff924d8c91d89eafa6f5d21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1057ede333d472e928bf26f119363a8",
              "IPY_MODEL_5291ad402b5e49ccb9901fbd01b22fd5",
              "IPY_MODEL_920ce00a1ab94bb881fe720826d11b25"
            ],
            "layout": "IPY_MODEL_37d5bcfa8baf49a8a7cb4319e4878644"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}